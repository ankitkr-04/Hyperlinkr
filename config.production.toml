# config.production.toml
environment = "production"

# Use dragonfly service in Docker compose
database_urls = ["redis://dragonfly:6379"]

# The public-facing URL for your service
base_url = "http://localhost:3000"

# Your container port
app_port = 3000

[cache]
# Tuning for high throughput in prod
l1_capacity         = 100_000
l2_capacity         = 1_000_000
bloom_bits          = 10_485_760  # ~10M bits
bloom_expected      = 1_000_000
bloom_shards        = 16
bloom_block_size    = 256
redis_pool_size     = 256
ttl_seconds         = 86_400      # 24 hours
max_failures        = 10
retry_interval_secs = 60
redis_command_timeout_secs = 2
redis_max_feed_count = 500
redis_broadcast_channel_capacity = 64
redis_max_command_attempts = 5
redis_connection_timeout_ms = 15000
redis_reconnect_max_attempts = 5
redis_reconnect_delay_ms = 200
redis_reconnect_max_delay_ms = 1000
sled_path = "./data/cache.sled"
sled_cache_bytes = 134217728
sled_flush_ms = 600000
sled_snapshot_ttl_secs = 5
sled_compression = true
use_sled = true
geoip_mmdb_path = "/path/to/GeoLite2-City.mmdb"
geo_hot_capacity = 500000
geo_ttl_seconds = 7200
geo_evict_interval_secs = 120

[rate_limit]
# More generous limits or driven by business needs
shorten_requests_per_minute  = 60
redirect_requests_per_minute = 100_000

[codegen]
shard_bits    = 14
max_attempts  = 8

[analytics]
# Flush more frequently if you care about near‐real‐time stats
flush_interval_ms   = 500
batch_size          = 50_000
max_batch_size_ms   = 2_000
max_batch_size      = 50_000

[security]
global_admins = []
jwt_secret = "0ecEuxack4XAdudiWTWXT3UocVEFhPZBaE0PhIJk3M3PNIfk5BnM+1WSYb0PaPaDCpApBRCPmrH89wDJNjQdyvkl6rEHoebJbmnYf+GqHA2WM6LqhNG+LCAHke8NFRnnlyHEhvr3KiJpQSKR0yWA8jqENpdLjVury+OknAJvQptoANSdIY8uF0FXU0kHLpnxdJ9HXRdyH0A3NTYX+EP9x8Jo3G5ymweJdLp/KUSHBjJGnAsHZAWlg9bOrqIEjau1VwUdDuFrv7yRMZYLBQsa6MRCZ09eRABl5MvqBMs/B8O3tYwUKeP04GqxwI2k5mk2qgMBPpij/zi5iKhDQ="
token_expiry_secs = 86400
domain = "localhost"
subdomains = ["api"]
